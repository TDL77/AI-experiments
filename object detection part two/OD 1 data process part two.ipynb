{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b920e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#импортируем разное\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b71a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/users/user/AI tests/krasnoteh_OD/images/IMG_20230812_135652.xml', 'C:/users/user/AI tests/krasnoteh_OD/images/IMG_20230812_135654.xml', 'C:/users/user/AI tests/krasnoteh_OD/images/IMG_20230812_135750.xml', 'C:/users/user/AI tests/krasnoteh_OD/images/IMG_20230812_135826.xml', 'C:/users/user/AI tests/krasnoteh_OD/images/IMG_20230812_135829.xml']\n"
     ]
    }
   ],
   "source": [
    "#преобразуем папку в tfrecord\n",
    "#приводит количество рамок к целевому значению\n",
    "goal = 10\n",
    "\n",
    "fn = \"C:/users/user/AI tests/krasnoteh_OD/images\"\n",
    "#формируем список всех xml файлов в папке\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'l'] \n",
    "print(p[:5])\n",
    "\n",
    "    \n",
    "def load_img(img):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)/256\n",
    "    img = tf.image.resize(img,(128,128))\n",
    "    return img\n",
    "    \n",
    "#создаем запись\n",
    "writer = tf.io.TFRecordWriter('bounding_box_dataset.tfrecord')\n",
    "\n",
    "\n",
    "\n",
    "for xml in p:\n",
    "    tree = ET.parse(xml) #адрес файла\n",
    "    root=tree.getroot()   #парсим\n",
    "    num_objects = len(root)-6\n",
    "    cords = []\n",
    "    w = int(root[4][0].text) #ширина x\n",
    "    h = int(root[4][1].text) #высота y\n",
    "    \n",
    "    positions = []\n",
    "    p = 0\n",
    "    while len(positions)<goal:\n",
    "        positions.append(p)\n",
    "        p+=1\n",
    "        if p==num_objects:\n",
    "            p = 0\n",
    "    \n",
    "    for num in positions:\n",
    "        object_cords = []\n",
    "        #нормализуем координаты от -1 до 1, опираясь на исходные координаты\n",
    "        object_cords.append(int(root[num+6][4][0].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+6][4][1].text)/h*2-1)\n",
    "        object_cords.append(int(root[num+6][4][2].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+6][4][3].text)/h*2-1)\n",
    "        cords.append(object_cords)\n",
    "\n",
    "    img = load_img(root[2].text)\n",
    "    #готовим данные, представляем в байтовом виде\n",
    "    serialized_img = tf.io.serialize_tensor(img).numpy()\n",
    "    serialized_cords = tf.io.serialize_tensor(cords).numpy()\n",
    "    #собираем экзепмляр\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_img])),\n",
    "        'cords': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_cords]))\n",
    "    }))\n",
    "\n",
    "    #записываем в запись\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94516e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#преобразуем папку в tfrecord для классификарора\n",
    "\n",
    "namespace = {'NOTHING': 0, 'm': 1 , 'c': 2 }\n",
    "\n",
    "fn = \"C:/users/user/AI tests/krasnoteh_OD/images\"\n",
    "#формируем список всех xml файлов в папке\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'l'] \n",
    "\n",
    "    \n",
    "def load_img(img):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)/256\n",
    "    img = tf.image.resize(img,(1024,1024))\n",
    "    return img\n",
    "    \n",
    "#создаем запись\n",
    "writer = tf.io.TFRecordWriter('classifier_dataset.tfrecord')\n",
    "\n",
    "def saveinrecord(img, name):\n",
    "    #готовим данные, представляем в байтовом виде\n",
    "    serialized_img = tf.io.serialize_tensor(img).numpy()\n",
    "    serialized_name = tf.io.serialize_tensor(name).numpy()\n",
    "    #собираем экзепмляр\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_img])),\n",
    "        'name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_name]))\n",
    "    }))\n",
    "\n",
    "    #записываем в запись\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "for xml in p:\n",
    "    tree = ET.parse(xml) #адрес файла\n",
    "    root=tree.getroot()   #парсим\n",
    "    num_objects = len(root)-6\n",
    "    \n",
    "    w = int(root[4][0].text) #ширина x\n",
    "    h = int(root[4][1].text) #высота y\n",
    "    \n",
    "    img = load_img(root[2].text)\n",
    "    for num in range(num_objects):\n",
    "        xmin = tf.clip_by_value(int(int(root[num+6][4][0].text)/w*1024), 0, 1024)\n",
    "        ymin = tf.clip_by_value(int(int(root[num+6][4][1].text)/h*1024), 0, 1024)\n",
    "        xmax = tf.clip_by_value(int(int(root[num+6][4][2].text)/w*1024), 0, 1024)\n",
    "        ymax = tf.clip_by_value(int(int(root[num+6][4][3].text)/h*1024), 0, 1024)\n",
    "        \n",
    "        \n",
    "        offset_height = ymin\n",
    "        offset_width = xmin\n",
    "        \n",
    "        target_height = ymax - ymin \n",
    "        target_width = xmax - xmin \n",
    "\n",
    "        cropped = tf.image.crop_to_bounding_box(img, offset_height, offset_width, target_height, target_width)\n",
    "        cropped = tf.image.resize(cropped,(128,128))\n",
    "        \n",
    "        name = namespace[root[num+6][0].text]\n",
    "        \n",
    "        saveinrecord(cropped, name)\n",
    "        \n",
    "    #создадим и рамки фона\n",
    "    counter = 0\n",
    "    goal = 5\n",
    "    \n",
    "    while counter < goal:\n",
    "        #сгенерим случайные координаты рамки\n",
    "        gxmin = random.randint(1, 900)\n",
    "        gymin = random.randint(1, 900)\n",
    "        gxsize = random.randint(10, 100)\n",
    "        gysize = random.randint(10, 100)\n",
    "        \n",
    "        gxmax = gxmin + gxsize\n",
    "        gymax = gymin + gysize\n",
    "        \n",
    "        #а вдруг рамка пересекается с реальной?\n",
    "        notintersect = True\n",
    "        \n",
    "        for num in range(num_objects):\n",
    "            xmin = tf.clip_by_value(int(int(root[num+6][4][0].text)/w*1024), 0, 1024)\n",
    "            ymin = tf.clip_by_value(int(int(root[num+6][4][1].text)/h*1024), 0, 1024)\n",
    "            xmax = tf.clip_by_value(int(int(root[num+6][4][2].text)/w*1024), 0, 1024)\n",
    "            ymax = tf.clip_by_value(int(int(root[num+6][4][3].text)/h*1024), 0, 1024)\n",
    "            \n",
    "            x_overlap = tf.maximum(0, tf.minimum(gxmax, xmax) - tf.maximum(gxmin, xmin))\n",
    "            y_overlap = tf.maximum(0, tf.minimum(gymax, ymax) - tf.maximum(gymin, ymin))\n",
    "            if x_overlap > 0 and y_overlap>0:\n",
    "                notintersect = False\n",
    "                break\n",
    "                \n",
    "        if notintersect:\n",
    "            cropped = tf.image.crop_to_bounding_box(img, gymin, gxmin, gysize, gxsize)\n",
    "            cropped = tf.image.resize(cropped,(128,128)) \n",
    "            name = 0\n",
    "            saveinrecord(cropped, name)\n",
    "            counter+=1\n",
    "            \n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3ebc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a08594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#прочитаем запись\n",
    "dataset = tf.data.TFRecordDataset('classifier_dataset.tfrecord')\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    #нужно описать приходящий экземпляр\n",
    "    #имена элементов как при записи\n",
    "    feature_description = {\n",
    "        'img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'name': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_record = tf.io.parse_single_example(record, feature_description)\n",
    "    img = tf.io.parse_tensor(parsed_record['img'], out_type=tf.float32)\n",
    "    name = tf.io.parse_tensor(parsed_record['name'], out_type=tf.int32)\n",
    "    return img, name\n",
    "\n",
    "#пройдемся по записи и распакуем ее\n",
    "dataset = dataset.map(parse_record)\n",
    "\n",
    "#что-нибудь выведем\n",
    "for i, c in dataset.take(1):\n",
    "    print(i.shape)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717cb48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
